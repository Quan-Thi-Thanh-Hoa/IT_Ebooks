{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong bài học này, chúng ta sẽ cùng nhau xây dựng một neural network ở dạng hoàn chỉnh với L hidden layer (lớp ẩn) cũng như các công thức tính toán lan truyền xuôi và lan truyền ngược. Nguyên nhân tại sao chúng ta cần xây dựng các mô hình với nhiều layer cũng sẽ được cắt nghĩa và giải thích thông qua việc liên tưởng kiến trúc NN với não bộ của con người. Khái niệm hyperparameters (siêu tham số) lần đầu tiên được giới thiệu với các bạn học viên, mở ra các bài học tiếp theo về lý thuyết tối ưu có sự liên quan chặt chẽ đến các hyperparameters này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mạng nơron nông (Shallow NN) là mạng nơron có 1 hoặc 2 lớp. Mạng nơron sâu (Deep NN) là mạng nơron có từ 3 lớp trở lên.\n",
    "\n",
    "Một số ký hiệu được sử dụng trong bài học:\n",
    "\n",
    "- L để biểu thị số lớp trong một mạng nơron\n",
    "- n[l] là số nơron trong một lớp cụ thể\n",
    "- n[0] biểu thị số lớp nơron đầu vào\n",
    "- n[L] biểu thị số lớp nơron đầu ra\n",
    "- g[l] là hàm kích hoạt\n",
    "- a[l] = g[l](z[l])\n",
    "- Trọng số w[l] được dùng cho z[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy, chúng ta có:\n",
    "- Vectơ n có shape (1, Số lớp + 1)\n",
    "- Vectơ g có shape (1, Số lớp)\n",
    "- Danh sách các shape w khác nhau dựa trên số nơron ở lớp trước và lớp hiện tại\n",
    "- Danh sách các shape b khác nhau dựa trên số nơron ở lớp hiện tại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deep L-layer Neural Network](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/7dP6E/deep-l-layer-neural-network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quy tắc lan truyền xuôi với **1** đầu vào:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Q](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Science%20%2FDSP303x_1.2_VN%2FContent_Image%2FDSP303x_1.2_L09_H01.png?alt=media&token=daba312e-6135-45a9-b607-57c9148def25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quy tắc lan truyền xuôi với **m** đầu vào:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![E](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Science%20%2FDSP303x_1.2_VN%2FContent_Image%2FDSP303x_1.2_L09_H02.png?alt=media&token=8e0c690d-a57b-49a1-80e3-87ae6e8b0e7a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta không thể tính toàn bộ các lớp lan truyền xuôi mà không cần vòng lặp for, do đó, chúng ta sẽ cần vòng lặp for ở đây."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Forward Propagation in a Deep Network](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/MijzH/forward-propagation-in-a-deep-network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cần tìm ra kích thước của ma trận vì nó rất quan trọng. Cách tính toán kích thước ma trận tốt nhất là ghi ra giấy:\n",
    "\n",
    "- Kích thước của W là (n[l],n[l-1])\n",
    "- Kích thước của b là (n[l],1)\n",
    "- dw có shape tương tự với W trong khi db có shape tương tự với b\n",
    "- Kích thước của Z[l], A[l], dZ[l] và dA[l] là (n[l],m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Getting your Matrix Dimensions Right](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/Rz47X/getting-your-matrix-dimensions-right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong video này, chúng ta sẽ thảo luận lý do mạng nơron sâu hoạt động tốt. \n",
    "\n",
    "Mạng nơron sâu tạo liên hệ với dữ liệu từ đơn giản tới phức tạp. Ở từng lớp, nó cố tạo quan hệ với lớp trước đó, ví dụ:\n",
    "\n",
    "- Ứng dụng nhận diện khuôn mặt (Face recognition): Hình ảnh => Các cạnh => Các bộ phận trên khuôn mặt => Các khuôn mặt => Khuôn mặt mong muốn.\n",
    "- Ứng dụng nhận diện âm thanh (Audio recognition): Âm thanh => Các đặc trưng âm thanh ở mức độ thấp (sss,bb) => Phonemes  m vị => Từ => Câu.\n",
    "\n",
    "Các nhà nghiên cứu nơron cho rằng mạng nơron sâu “tư duy” như não bộ (đơn giản ⇒ phức tạp). Khi bắt đầu ứng dụng, chúng ta chưa cần bắt đầu trực tiếp bằng nhiều lớp ẩn. Hãy thử giải pháp đơn giản nhất (chẳng hạn: Hồi quy logistic) rồi thử mạng nơron nông, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Why Deep Representations?](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/rz9xJ/why-deep-representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lan truyền xuôi và ngược cho một lớp l:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![E](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Science%20%2FDSP303x_1.2_VN%2FContent_Image%2FDSP303x_1.2_L09_H03.png?alt=media&token=526b10c0-c489-4797-b457-6bf70fa5b8f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Building Blocks of Deep Neural Networks](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/uGCun/building-blocks-of-deep-neural-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mã giả cho lan truyền xuôi với lớp l:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Science%20%2FDSP303x_1.2_VN%2FContent_Image%2FDSP303x_1.2_L09_H04.png?alt=media&token=a0132634-2feb-494c-a02a-2f0f8376ce15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mã giả cho lan truyền ngược với lớp l:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Science%20%2FDSP303x_1.2_VN%2FContent_Image%2FDSP303x_1.2_L09_H05.png?alt=media&token=12ce2e95-2423-4071-a191-1a57e95d42d6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu sử dụng hàm mất mát thì: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A](https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Science%20%2FDSP303x_1.2_VN%2FContent_Image%2FDSP303x_1.2_L09_H06.png?alt=media&token=530f0996-5aff-4d8d-82f5-1fa934ab897c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Forward and Backward Propagation](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/znwiG/forward-and-backward-propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Các tham số và siêu tham số trong DNN**\n",
    "\n",
    "Các tham số chính của mạng nơron là w và b.\n",
    "\n",
    "Siêu tham số (các tham số kiểm soát thuật toán) là:\n",
    "\n",
    "- Tốc độ học\n",
    "- Số lần lặp\n",
    "- Số lớp ẩn L\n",
    "- Số đơn vị ẩn n\n",
    "- Chọn hàm kích hoạt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước kia trong DL và ML, tốc độ học thường được gọi là tham số, nhưng hiện giờ (mọi người gọi nó) là siêu tham số.\n",
    "\n",
    "Chúng ta sẽ xem cách tối ưu hóa siêu tham số sau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Parameters vs Hyperparameters](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/TBvb5/parameters-vs-hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví von “DNN giống như não bộ” đã trở thành giải thích quá đơn giản. Có sự tương đồng đơn giản giữa đơn vị logistic và nơron riêng lẻ trong não. Hiện nay, không ai hiểu hết cách nơron não bộ hoạt động, không ai biết rõ não bộ có bao nhiêu nơron.\n",
    "\n",
    "Theo quan điểm của Andrew, học sâu rất giỏi trong việc học các hàm phức tạp, linh hoạt để nghiên cứu ánh xạ X tới Y, ánh xạ đầu vào-đầu ra (học có giám sát). Mạng nơron là một biểu diễn nhỏ cho cách não bộ hoạt động. Mô hình tương tự nhất với não bộ là trong thị giác máy tính (CNN), lĩnh vực thị giác máy tính lấy khá nhiều cảm hứng từ não bộ con người."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[What does this have to do with the brain?](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/obJnR/what-does-this-have-to-do-with-the-brain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ad7f758c7f2ebdda2cc4f553f1363ed8fbfe288e0aece9aaf2ec73dff90b611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
